#!/usr/bin/env python3
"""
éªŒè¯è‡ªåŠ¨ä¿®å¤åŠŸèƒ½çš„åŸºæœ¬æµ‹è¯•
"""
import json
import tempfile
from pathlib import Path

def test_prompt_builder_repair():
    """æµ‹è¯• PromptBuilder çš„ä¿®å¤åŠŸèƒ½"""
    print("=== æµ‹è¯• PromptBuilder ä¿®å¤åŠŸèƒ½ ===")
    
    # æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    
    try:
        from generator.prompt_builder import PromptBuilder
        
        builder = PromptBuilder()
        
        # æ¨¡æ‹Ÿæµ‹è¯•å¥—ä»¶
        suite = {
            "suite_id": "test-001",
            "suite_name": "Test Suite",
            "context": {
                "entry_point": "tests/test_example.py"
            }
        }
        
        # æ¨¡æ‹Ÿæœ‰é—®é¢˜çš„ä»£ç 
        current_code = """def test_example():
    # ç¼ºå°‘ requests å¯¼å…¥
    response = requests.post("http://localhost:5000/api/calc", 
                           json={"operation": "add", "operands": [2, 3]})
    assert response.status_code == 200
    assert response.json()["result"] == 5"""
        
        # æ¨¡æ‹Ÿå¤±è´¥æ‘˜è¦
        summary = {
            "totals": {"failed": 1, "passed": 0},
            "failures": [{
                "nodeid": "test_example.py::test_example", 
                "outcome": "failed",
                "longrepr": "NameError: name 'requests' is not defined"
            }]
        }
        
        # æ¨¡æ‹Ÿæ—¥å¿—
        logs = {
            "pytest_stdout": "FAILED test_example.py::test_example - NameError: name 'requests' is not defined",
            "pytest_stderr": "NameError: name 'requests' is not defined"
        }
        
        # æµ‹è¯•ä¿®å¤æç¤ºè¯æ„å»º
        system_prompt, user_prompt = builder.build_repair_prompts(
            suite, current_code, summary, logs
        )
        
        print("âœ… ä¿®å¤æç¤ºè¯æ„å»ºæˆåŠŸ")
        print(f"ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)}")
        print(f"ç”¨æˆ·æç¤ºè¯é•¿åº¦: {len(user_prompt)}")
        
        # æ£€æŸ¥æç¤ºè¯å†…å®¹
        assert "ä¿®å¤" in system_prompt
        assert "requests" in user_prompt
        assert "NameError" in user_prompt
        
        print("âœ… æç¤ºè¯å†…å®¹éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ PromptBuilder æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_pipeline_imports():
    """æµ‹è¯• pipeline æ¨¡å—å¯¼å…¥"""
    print("\n=== æµ‹è¯• Pipeline æ¨¡å—å¯¼å…¥ ===")
    
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    
    try:
        from auto_exec.pipeline import try_auto_fix, collect_failure_context
        print("âœ… pipeline æ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ pipeline æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_mock_llm_client():
    """æµ‹è¯• Mock LLM å®¢æˆ·ç«¯"""
    print("\n=== æµ‹è¯• Mock LLM å®¢æˆ·ç«¯ ===")
    
    import sys
    sys.path.insert(0, str(Path(__file__).parent))
    
    try:
        from generator.llm_client import LLMClient
        
        # åˆ›å»º mock å“åº”æ–‡ä»¶
        mock_response = '''```python
import requests
import pytest

def test_example():
    response = requests.post("http://localhost:5000/api/calc", 
                           json={"operation": "add", "operands": [2, 3]})
    assert response.status_code == 200
    assert response.json()["result"] == 5
```'''
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
            f.write(mock_response)
            mock_file = f.name
        
        try:
            # åˆ›å»º mock å®¢æˆ·ç«¯
            client = LLMClient(mode="mock", mock_response_path=mock_file)
            
            # æµ‹è¯•ç”Ÿæˆä»£ç 
            response = client.generate_code("ç³»ç»Ÿæç¤ºè¯", "ç”¨æˆ·æç¤ºè¯")
            
            print("âœ… Mock LLM å®¢æˆ·ç«¯æµ‹è¯•æˆåŠŸ")
            print(f"å“åº”é•¿åº¦: {len(response)}")
            assert "import requests" in response
            print("âœ… å“åº”å†…å®¹éªŒè¯é€šè¿‡")
            
            return True
        finally:
            Path(mock_file).unlink(missing_ok=True)
            
    except Exception as e:
        print(f"âŒ Mock LLM å®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹éªŒè¯è‡ªåŠ¨ä¿®å¤åŠŸèƒ½...\n")
    
    tests = [
        test_prompt_builder_repair,
        test_pipeline_imports,
        test_mock_llm_client,
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        if test():
            passed += 1
        print()
    
    print(f"éªŒè¯ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼è‡ªåŠ¨ä¿®å¤åŠŸèƒ½å·²å°±ç»ªã€‚")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("1. å‘½ä»¤è¡Œ: python -m auto_exec.pipeline --suite test.json --mode mock --auto-fix")
        print("2. Gradioç•Œé¢: å¯ç”¨'è‡ªåŠ¨ä¿®å¤'å¤é€‰æ¡†")
    else:
        print("âš ï¸ éƒ¨åˆ†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ¨¡å—ã€‚")

if __name__ == "__main__":
    main()
